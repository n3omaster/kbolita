# Kbolita

Sistema automatizado de scraping y almacenamiento de resultados de loterÃ­a de Florida (Pick 3 y Pick 4). La aplicaciÃ³n extrae datos de sorteos diarios, los almacena en una base de datos y envÃ­a notificaciones mediante webhooks.

## ğŸ¯ CaracterÃ­sticas

- **Scraping automatizado**: ExtracciÃ³n de resultados de Pick 3 y Pick 4 desde el sitio oficial de Florida Lottery
- **Renderizado dinÃ¡mico**: Utiliza Puppeteer para procesar contenido JavaScript
- **Almacenamiento persistente**: Guarda resultados en Supabase con detecciÃ³n de duplicados
- **IntegraciÃ³n con webhooks**: EnvÃ­a notificaciones a servicios externos (n8n) tras cada actualizaciÃ³n
- **API RESTful**: Endpoints para scraping y recuperaciÃ³n de datos

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Framework**: Next.js 16.1.0
- **Runtime**: React 19.2.3
- **Base de datos**: Supabase (PostgreSQL)
- **Scraping**: Puppeteer 24.34.0, Cheerio 1.1.2
- **Bot**: Grammy 1.38.4 (Telegram)
- **Estilos**: Tailwind CSS 4

## ğŸ“‹ Requisitos Previos

- Node.js 18+ 
- npm o yarn
- Cuenta de Supabase configurada
- Chromium o Google Chrome instalado en el sistema (para Puppeteer)

## ğŸš€ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone <repository-url>
cd kbolita
```

2. Instalar dependencias:
```bash
npm install
```

3. Configurar variables de entorno:
Crear un archivo `.env.local` con las siguientes variables:

```env
SUPABASE_URL=tu_url_de_supabase
SUPABASE_SERVICE_KEY=tu_service_key_de_supabase
```

4. Ejecutar en modo desarrollo:
```bash
npm run dev
```

La aplicaciÃ³n estarÃ¡ disponible en [http://localhost:3000](http://localhost:3000)

## ğŸ“¡ API Endpoints

### `GET /api/scrape?game={PICK3|PICK4}`

Extrae los resultados mÃ¡s recientes del juego especificado desde el sitio web de Florida Lottery.

**ParÃ¡metros:**
- `game` (query): `PICK3` o `PICK4` (por defecto: `PICK3`)

**Respuesta:**
```json
{
  "ok": true,
  "game": "PICK3",
  "count": 2,
  "results": [
    {
      "game": "PICK3",
      "drawTime": "MIDDAY",
      "date": "2025-12-19",
      "numbers": "123",
      "fireball": "4"
    }
  ]
}
```

### `POST /api/retrieve`

Ejecuta el scraping de ambos juegos (Pick 3 y Pick 4), almacena los resultados en la base de datos y envÃ­a un webhook con el resumen.

**Respuesta:**
```json
{
  "ok": true,
  "summary": {
    "pick3": 2,
    "pick4": 2,
    "total": 4,
    "stored": 3,
    "skipped": 1
  },
  "results": [...]
}
```

## ğŸ—„ï¸ Estructura de Base de Datos

La tabla `games` en Supabase debe tener la siguiente estructura:

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| `id` | UUID | Identificador Ãºnico |
| `type` | TEXT | Tipo de juego (`PICK3` o `PICK4`) |
| `draw_date` | DATE | Fecha del sorteo |
| `draw_time` | TEXT | Hora del sorteo (`MIDDAY` o `EVENING`) |
| `result` | TEXT | NÃºmeros ganadores |
| `fireball` | TEXT | NÃºmero Fireball (opcional) |

**Clave Ãºnica**: `(type, draw_date, draw_time)`

## ğŸ”§ ConfiguraciÃ³n

### Puppeteer y Chromium

El sistema intenta usar Chromium del sistema antes de recurrir al empaquetado por Puppeteer. Busca en las siguientes rutas:

- `/usr/bin/chromium`
- `/usr/bin/chromium-browser`
- `/usr/bin/google-chrome`
- `/usr/bin/google-chrome-stable`

### Webhooks

El endpoint `/api/retrieve` envÃ­a automÃ¡ticamente un webhook a la URL configurada en el cÃ³digo. Actualizar la variable `webhookUrl` en `app/api/retrieve/route.js` segÃºn sea necesario.

## ğŸ“ Scripts Disponibles

```bash
npm run dev      # Inicia el servidor de desarrollo
npm run build    # Construye la aplicaciÃ³n para producciÃ³n
npm run start    # Inicia el servidor de producciÃ³n
npm run lint     # Ejecuta el linter
```

## ğŸ—ï¸ Estructura del Proyecto

```
kbolita/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ scrape/      # Endpoint de scraping
â”‚   â”‚   â”œâ”€â”€ retrieve/    # Endpoint de recuperaciÃ³n y almacenamiento
â”‚   â”‚   â””â”€â”€ tgbot/       # Endpoint del bot de Telegram (en desarrollo)
â”‚   â”œâ”€â”€ page.js          # PÃ¡gina principal
â”‚   â””â”€â”€ layout.js        # Layout de la aplicaciÃ³n
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ supabase.ts      # Cliente de Supabase
â”‚   â””â”€â”€ tgbot.js         # ConfiguraciÃ³n del bot de Telegram
â””â”€â”€ public/              # Archivos estÃ¡ticos
```

## ğŸ” Funcionamiento

1. **Scraping**: El endpoint `/api/scrape` utiliza Puppeteer para cargar la pÃ¡gina de Florida Lottery y esperar a que el contenido dinÃ¡mico (Vue.js) se renderice completamente.

2. **Parsing**: Cheerio extrae los datos estructurados (fecha, hora, nÃºmeros, fireball) del HTML renderizado.

3. **Almacenamiento**: El endpoint `/api/retrieve` verifica duplicados antes de insertar nuevos registros en Supabase.

4. **NotificaciÃ³n**: Tras almacenar los datos, se envÃ­a un webhook con el resumen de la operaciÃ³n.

## ğŸš¨ Manejo de Errores

- El sistema detecta y omite resultados duplicados automÃ¡ticamente
- Los errores de scraping se registran en la consola y se retornan en la respuesta JSON
- Puppeteer se configura con opciones optimizadas para entornos sin interfaz grÃ¡fica

## ğŸ“„ Licencia

Este proyecto es privado.

## ğŸ‘¤ Autor

Desarrollado para automatizaciÃ³n de recolecciÃ³n de datos de loterÃ­a.
